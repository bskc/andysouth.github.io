---
layout: post
title: Box cox transformation
published: false
status: process
draft: false
tags: R 
output:
  prettydoc::html_pretty:
    theme: leonids
    highlight: github
---

In order to perform ordinary least sqaures regression, there are certain assumptions that need to be considered before building a modeling. Assumptions regarding residuals, such as normal distribution, constant variance i.e homoscadaticity need to be checked while building a model. However, there will be times when the assumptions of OLS are violated by data. In such instances data transformation can be employed to transform data from non-linear distribution to linear distribution. In this post we will look at one such technique called "Box Cox" transformation.



```{r}
library(readr) # importing csv files
library(MASS) # Boxcox function
library(car) # qqPlot function
library(moments) # skeweness and kurtosis functions
```

```{r, message=FALSE}
TGT <- read_csv("C:/Users/welcome/Downloads/TGT.csv")

attach(TGT)
```

## Data preparation

1. As the class of TAT is integer, it is converted to numeric
2. Grades "ASE1", "ASE2", "ASE3","ASE4", "ASE5" are changed to 1, 2, 3, 4 & 5 respectively, and class of Grade is converted from character to numeric.
```{r}

TGT[,"TAT"] <- as.numeric(TAT) # convert to num


TGT[which(GRADE == 'ASE1'), "GRADE"] <- 1

TGT[which(GRADE == 'ASE2'), "GRADE"] <- 2

TGT[which(GRADE == 'ASE3'), "GRADE"] <- 3

TGT[which(GRADE == 'ASE4'), "GRADE"] <- 4

TGT[which(GRADE == 'ASE5'), "GRADE"] <- 5

TGT[,"GRADE"] <- as.numeric(TGT$GRADE)
```

## Model fitting ( Before transformation)

TAT is regressed with GRADE with out any data tranformation.
```{r}
f <- lm(TAT ~ as.factor(GRADE))

plot(f$fitted.values,  rstandard(f)) # Examine raw residuals  vs fitted values
```


From the above plot, it appears that there is a trend in the residuals, which takes the shape of an outward funnel.
```{r}
hist(f$residuals) # examine histogram of raw residuals
```

Histogram indicate distribution of raw residuals is postively skewed. 
```{r}
qqPlot(rstandard(f)) # examine quantile-quantile plot for raw residuals
```

```{r}
skewness(f$residuals) 

```

```{r}
kurtosis(f$residuals) 
```



## Estimation of likelihood function
```{r}
b <- boxcox(TAT ~ GRADE)

```
```{r}
lambda <- b$x # lambda values

lik <- b$y # log likelihood values for SSE

bc <- cbind(lambda, lik) # combine lambda and lik

sorted_bc <- bc[order(-lik),] # values are sorted to identify the lambda value for the maximum log likelihood for obtaining minimized SSE

head(sorted_bc, n = 10)
```

The lambda value for for the maximum log likeihood for obtaining minimized SSE is 0.38( also can be seen in the box cox plot above)



## Model fitting (After transformation)

After identifying the lambda value, which is 0.38, lets fit the model with the transformed data.
```{r}
f1 <- lm(TAT^(0.38) ~ as.factor(GRADE))

plot(f1$fitted.values,  rstandard(f1)) # Examine raw residuals vs fitted values
```

The distribution of residuals around the fitted line has improved from the previous model. Nearly close to constant variance.
```{r}
hist(f1$residuals) # examine histogram of raw residuals
```

Histogram indicate distribution of raw residuals is very close to normal distribution.

```{r}
qqPlot(rstandard(f1)) # examine quantile-quantile plot for raw residuals
```

```{r}
skewness(f1$residuals) 
```

```{r}
kurtosis(f1$residuals) 
```


The adjusted R square value has improved from model fitted with untransformed data to model fitted with transformed data. 
```{r}
adj_rsq1 <- summary(f)$adj.r.squared

adj_rsq2 <- summary(f1)$adj.r.squared

cat("Adjusted R-Square (before transformation):", adj_rsq1, "Adjusted R-Square (after transformation):", adj_rsq2, sep = "\n")
```

